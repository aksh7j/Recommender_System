# Import necessary libraries
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel
from surprise import Reader, Dataset, SVD
from surprise.model_selection import cross_validate

# --- Data Loading ---
# Load the movie and rating datasets from CSV files.
# Ensure 'movies.csv' and 'ratings.csv' are in the same directory.

    movies_df = pd.read_csv('movies.csv')
    ratings_df = pd.read_csv('ratings.csv')


# Display the first few rows to verify data loading
print('Movies Dataset:')
print(movies_df.head())
print('\nRatings Dataset:')
print(ratings_df.head())


# --- Content-Based Filtering ---
# This method recommends movies based on their genre similarity.

# Clean up genres data by replacing the placeholder for missing genres.
movies_df['genres'] = movies_df['genres'].replace('(no genres listed)', '')

# Use TF-IDF to convert the 'genres' string into a matrix of feature vectors.
tfidf_vectorizer = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf_vectorizer.fit_transform(movies_df['genres'])

# Calculate cosine similarity between all movies based on their genre vectors.
cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)

# Create a map of movie titles to their index for quick lookups.
indices = pd.Series(movies_df.index, index=movies_df['title']).drop_duplicates()

def get_content_based_recommendations(title, cosine_sim=cosine_sim):
    """Gets top 10 similar movies based on content (genres)."""
    # Find the index of the input movie title.
    if title not in indices:
        return f"Movie with title '{title}' not found."
    idx = indices[title]

    # Get similarity scores for the movie against all other movies.
    sim_scores = list(enumerate(cosine_sim[idx]))

    # Sort movies by similarity score in descending order.
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    # Get the top 10 most similar movies (excluding the movie itself).
    sim_scores = sim_scores[1:11]

    # Get the indices of the recommended movies.
    movie_indices = [i[0] for i in sim_scores]

    # Return the titles of the recommended movies.
    return movies_df['title'].iloc[movie_indices]

# Example: Get recommendations for 'Toy Story (1995)'.
print('\n' + '-'*50)
print('Content-Based Recommendations for "Toy Story (1995)":')
print(get_content_based_recommendations('Toy Story (1995)'))
print('-'*50)


# --- Collaborative Filtering ---
# This method uses user ratings to recommend movies.

# Prepare data for the Surprise library.
reader = Reader(rating_scale=(1, 5))
data = Dataset.load_from_df(ratings_df[['userId', 'movieId', 'rating']], reader)

# Use the SVD (Singular Value Decomposition) algorithm for matrix factorization.
svd = SVD()

# Train the SVD model on the entire dataset.
trainset = data.build_full_trainset()
svd.fit(trainset)

# Evaluate the model's performance using 5-fold cross-validation.
print('\n' + '-'*50)
print('Cross-validation results for SVD:')
cross_validate(svd, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)
print('-'*50)

# Example: Predict a rating for a specific user and movie.
user_id = 1
movie_id = 302 # Corresponds to 'Close Shave, A (1995)'
predicted_rating = svd.predict(user_id, movie_id).est
print(f'\nPredicted rating for user {user_id} on movie {movie_id}: {predicted_rating:.2f}')


# --- Hybrid Recommender System ---
# Combines content-based and collaborative filtering for improved recommendations.

def hybrid_recommendations(userId, title):
    """Recommends movies by filtering content-based results with collaborative predictions."""
    # Get initial recommendations based on content similarity.
    content_recs = get_content_based_recommendations(title)
    if isinstance(content_recs, str): # Handle case where movie title is not found.
        return content_recs
        
    content_recs_df = pd.DataFrame({'title': content_recs})
    
    # Get the movie IDs for the recommended movies.
    recs_with_ids = pd.merge(content_recs_df, movies_df, on='title')
    
    # Predict how the user would rate these content-based recommendations.
    recs_with_ids['predicted_rating'] = recs_with_ids['movieId'].apply(lambda x: svd.predict(userId, x).est)
    
    # Sort the recommendations by the predicted rating.
    recs_with_ids = recs_with_ids.sort_values(by='predicted_rating', ascending=False)
    
    return recs_with_ids[['title', 'genres', 'predicted_rating']]

# Example: Get hybrid recommendations.
print('\n' + '-'*50)
print('Hybrid Recommendations for user 1 based on "Toy Story (1995)":')
print(hybrid_recommendations(1, 'Toy Story (1995)'))
print('-'*50)


# --- Cold-Start Problem Solution ---
# For new users with no ratings, we recommend the most popular movies.

def get_popular_movies(min_ratings=100):
    """Gets popular movies, defined by a minimum number of ratings and high average score."""
    # Calculate the mean rating and rating count for each movie.
    movie_ratings = ratings_df.groupby('movieId')['rating'].agg(['mean', 'count']).reset_index()
    
    # Merge with the movies dataframe to get titles.
    popular_movies = pd.merge(movie_ratings, movies_df, on='movieId')
    
    # Filter out movies that don't meet the minimum rating count.
    popular_movies = popular_movies[popular_movies['count'] > min_ratings]
    
    # Sort the filtered movies by their average rating.
    popular_movies = popular_movies.sort_values(by='mean', ascending=False)
    
    return popular_movies

# Example: Get top 10 popular movies for a new user.
print('\n' + '-'*50)
print('Top 10 Popular Movies for New Users:')
print(get_popular_movies().head(10)[['title', 'genres', 'mean', 'count']])
print('-'*50)
